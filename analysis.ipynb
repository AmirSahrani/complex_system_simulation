{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criticality in the Cortex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-03T09:58:12.161271900Z",
     "start_time": "2024-02-03T09:58:11.877695300Z"
    }
   },
   "outputs": [],
   "source": [
    "'''Setup notebook environment -q flag suppresses output, if you want to see it, remove the -q flag'''\n",
    "%pip install -r requirements.txt -q\n",
    "from utils.plotting_utils import *\n",
    "from utils.data_utils import *\n",
    "from utils.utils import *\n",
    "from branching import BranchingNeurons\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import powerlaw\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "from cellular_automata import CA\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Branching model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first section of this notebook will be investigating the behavior of a branching model. This model is a simple branching process, where each neuron has a probability of firing, and if it does, it will fire to a number of other neurons. This is a simple model of the branching of neurons in the cortex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Files should be available in the data folder, if not, run the code below. It may take a while !!\n",
    "file = 'data/branching_data_densities.csv'\n",
    "if not os.path.exists(file):\n",
    "    for branching_ratio in tqdm(np.logspace(np.log10(0.5), np.log10(5), 20)):\n",
    "        for i in [0,1,3,5]:\n",
    "            kwargs = {\n",
    "                'N': 100,\n",
    "                'max_neighbors': 28,\n",
    "                'cooldown': i,\n",
    "                'branching_ratio': branching_ratio,\n",
    "                'visual': False,\n",
    "            }\n",
    "            data = simulate(BranchingNeurons, n_runs=10, duration=10000, **kwargs)\n",
    "            write_data(data, file)\n",
    "\n",
    "\n",
    "file = 'data/branching_data_final.csv'\n",
    "if not os.path.exists(file):\n",
    "    for branching_ratio in tqdm(np.logspace(np.log10(0.5), np.log10(5), 20)):\n",
    "        kwargs = {\n",
    "            'N': 2500,\n",
    "            'max_neighbors': 28,\n",
    "            'branching_ratio': branching_ratio,\n",
    "            'visual': False,\n",
    "        }\n",
    "        data = simulate(BranchingNeurons, n_runs=10, duration=10000, **kwargs)\n",
    "        write_data(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/branching_data_final.csv', header=0, index_col=0)\n",
    "data['mean_density'] = data['density'].apply(float)\n",
    "data['evalanche_duration'] = data['evalanche_duration'].apply(str_to_list)\n",
    "data['evalanche_size'] = data['evalanche_size'].apply(str_to_list)\n",
    "\n",
    "data['density_duration'] = data.apply(lambda x: get_density(x['evalanche_duration'])[0], axis=1)\n",
    "data['density_size'] = data.apply(lambda x: get_density(x['evalanche_size'])[0], axis=1)\n",
    "data['values_duration'] = data.apply(lambda x: get_density(x['evalanche_duration'])[1], axis=1)\n",
    "data['values_size'] = data.apply(lambda x: get_density(x['evalanche_size'])[1], axis=1)\n",
    "\n",
    "\n",
    "grouped_branching = data.groupby('branching_ratio').mean(numeric_only=True)\n",
    "critical_point = closest_index_to_value(grouped_branching.index, 1)\n",
    "critical_data = grouped_branching.loc[grouped_branching.index == grouped_branching.index[critical_point]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavior over time for different branching ratios\n",
    "We can see that for different branching ratios, the behavior of the system changes. For a branching ratio of 1.1 (because of system size we correct the branching ratio upward a little bit), the system is at a critical point, and the activations quickly increase but die out after a period of activiy. For a branching ratio of 0.8, the system will die out, and for a branching ratio of 2, the system tend to chaos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'N': 500,\n",
    "    'max_neighbors': 28,\n",
    "    'branching_ratio': None,\n",
    "    'visual': False,\n",
    "}\n",
    "plot_activity_per_time_step(10000, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the emperical branching ratio\n",
    "When we manually calculate the branching ratio, we find that the branching ratio does not the same as the one we set. This is because the branching ratio is a function of the system size, and the system size is not large enough to get a good estimate of the branching ratio. This is a common problem in the study of criticality in the cortex, and is known as the \"finite size effect\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_emperical_branching_ratio(grouped_branching)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase transition\n",
    "When plotting the mean activity of the system over time, we can see that the system goes through a phase transition at a branching ratio of 1. This is a critical point, and the system will go from a state of low activity to a state of high activity. This is a phase transition, and is a common feature of critical systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_density_vs_branching_ratio(grouped_branching, critical_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on the activity\n",
    "We noticed the mean activity of the system does not approach 1, we suspect this might also be because the system size is not large enough to get a good estimate of the mean activity. We also suspected the refractory period of the neurons might also affect the mean activity of the system, but looking at the figure below comparing the mean activity of the system for different refractory periods, we can see that the refractory period only decreases the mean activity of the system, and does not affect the phase transition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cooldowns = pd.read_csv('data/branching_data_densities.csv', header=0, index_col=0)\n",
    "grouped_cooldowns = data_cooldowns.groupby(['cooldown', 'branching_ratio']).agg({'density': ['mean', 'std']})\n",
    "\n",
    "\n",
    "plot_phase_transition_cooldowns(grouped_cooldowns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avalanche distributions\n",
    "Below we plot the avalanche distributions for their size and duration. In both we notice no statistically significant results for the power law distribution, which is a common feature of critical systems. Although we do note that the figures visually look very much like a power law distribution. We also see that around the branching ratio these distributions become more power law like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['avalanche_duration'] = data['evalanche_duration']\n",
    "data['avalanche_size'] = data['evalanche_size']\n",
    "loglog_plotting(\"avalanche_duration\", data, grouped_branching)\n",
    "loglog_plotting(\"avalanche_size\", data, grouped_branching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglog_plotting_size_duration(['evalanche_size', 'evalanche_duration'], data, grouped_branching)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information flow\n",
    "> We will be investigating the following information transfer properties of the branching model:\n",
    "> 1. The dynamic range of the information transfer between the input and the output layer \n",
    "> 2. The susceptibility of the information transfer, being measured as the total variance between the input and the output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information transfer between the input and the output layer\n",
    "The following code will be investigating the information transfer between the input and the output layer. We will be looking at the mutual information between the input and the output layer, and how it changes with the branching ratio. We will also be looking at the information transfer between the input and the output layer, and how it changes with the branching ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "branching_ratios = np.linspace(0.2, 3, 15)\n",
    "input_nums = list(range(1, 100, 2))\n",
    "mutual_infos = []\n",
    "dynamic_ranges = []\n",
    "susceptibilities = []\n",
    "susceptibilities_error = []\n",
    "\n",
    "for branching_ratio in branching_ratios:\n",
    "    kwargs = {\n",
    "        'N': 100,\n",
    "        'max_neighbors': 8,\n",
    "        'branching_ratio': branching_ratio,\n",
    "        'cooldown': 0,\n",
    "        'visual': False,\n",
    "    }\n",
    "    sim = BranchingNeurons(**kwargs)\n",
    "    output_nums = []\n",
    "    sus_list = []\n",
    "\n",
    "    for input_num in input_nums:\n",
    "        spike_history = []\n",
    "        for _ in range(10):\n",
    "            running_average = []\n",
    "            sim.reset()\n",
    "\n",
    "            neurons_to_activate = np.random.choice(sim.neurons, input_num, replace=False)\n",
    "\n",
    "            assert len(neurons_to_activate) == input_num\n",
    "\n",
    "            for neuron in neurons_to_activate:\n",
    "                neuron.active = True\n",
    "                sim.active.append(neuron)\n",
    "\n",
    "            for i in range(10):\n",
    "                sim.run(1, random_adding=False)\n",
    "                running_average.append(sum([neuron.active for neuron in sim.neurons]))\n",
    "\n",
    "            spike_history.append(np.mean(running_average))\n",
    "\n",
    "        output_nums.append(spike_history[-1])\n",
    "        sus_list.append(susceptibility(spike_history, 100))\n",
    "    mutual_infos.append(mutual_info(input_nums, output_nums))\n",
    "    dynamic_ranges.append(dynamic_range(output_nums))\n",
    "    susceptibilities.append(np.mean(sus_list))\n",
    "    susceptibilities_error.append(np.std(sus_list)/np.sqrt(len(sus_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can seee that as the branching ratio increase the information transfer between the input and the output layer increases. We can also see the susceptibility peak around the critical point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_range_plot(dynamic_ranges, branching_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "susceptibility_plot(susceptibilities, susceptibilities_error, branching_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### df: index, spikes_total, spikes_input, spikes_neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For different patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings1 = [\n",
    "    {\"name\": \"round_spiral\", \"params\": {\"threshold\": 4, \"refractory_period\": 5, \"probability_of_spontaneous_activity\": 0.02, \"max_distance\": 3, \"random_connection\": False}},\n",
    "    {\"name\": \"pulse_wave\", \"params\": {\"threshold\": 5, \"refractory_period\": 3, \"probability_of_spontaneous_activity\": 0.03, \"max_distance\": 3, \"random_connection\": False}},\n",
    "    {\"name\": \"synchronous\", \"params\": {\"threshold\": 3, \"refractory_period\": 5, \"probability_of_spontaneous_activity\": 0.015, \"max_distance\": 2.5, \"random_connection\": True}},\n",
    "    {\"name\": \"oscillatory\", \"params\": {\"threshold\": 2, \"refractory_period\": 4, \"probability_of_spontaneous_activity\": 0.02, \"max_distance\": 3, \"random_connection\": False}},\n",
    "    {\"name\": \"repeating\", \"params\": {\"threshold\": 2, \"refractory_period\": 4, \"probability_of_spontaneous_activity\": 0.02, \"max_distance\": 3, \"random_connection\": True}},\n",
    "    {\"name\": \"random\", \"params\": {\"threshold\": 5, \"refractory_period\": 5, \"probability_of_spontaneous_activity\": 0.02, \"max_distance\": 3, \"random_connection\": False}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collection to csv in df: spikes_input, spikes_neighbours, spikes_total per time step\n",
    "for setting in settings1:\n",
    "    ca = CA(grid_size=[50, 50], **setting['params'])\n",
    "    ca.run(10000)\n",
    "    path = f\"data/spikes_CA_{setting['name']}.csv\"\n",
    "    ca.write_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see what's the pattern like for different patterns\n",
    "paths = [f\"data/spikes_CA_{setting['name']}.csv\" for setting in settings1]\n",
    "for path in paths:\n",
    "    df = load_data_csv(path)\n",
    "    sigma = branching_prameter(df)\n",
    "    print(path, sigma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more parameters settings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### df: avalanche_size, avalanche_duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is used to store raster data, which is not used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for setting in settings2:\n",
    "    ca = CA(grid_size=[50, 50], **setting['params'])\n",
    "    ca.init_grid(\"random\", 4)\n",
    "    ca.run(10000)\n",
    "    path = f\"data/spikes_CA_avalanche/spikes_CA_{setting['name']}.csv\"\n",
    "    ca.collect_raster_data(10000, path) # This function: collect raster data was once used to collect raster data in csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is used to store raster data for different patterns, which is also used plot spike activity figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for setting in settings1:\n",
    "    ca = CA(grid_size=[20, 20], ** setting['params'])\n",
    "    ca.init_grid(\"random\", 4)\n",
    "    ca.run(1500)\n",
    "    path = f\"data/spikes_CA_avalanche_grid/spikes_CA_{setting['name']}.csv\"\n",
    "    df = ca.collect_raster_data(5000)\n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is used to store avalanche data, which is also used to plot power law distributions later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings3 = [{\"name\": f\"ref{ref}thresh{thresh}p{p}\", \n",
    "            \"params\": {\"threshold\": thresh, \n",
    "                        \"refractory_period\": ref, \n",
    "                        \"probability_of_spontaneous_activity\": p, \n",
    "                        \"max_distance\": 3, \n",
    "                        \"random_connection\": False}}\n",
    "            for ref in range(2, 8) for thresh in range(2, 8) for p in [0.015, 0.02, 0.025]]\n",
    "paths_avalanche = []\n",
    "settings4 = []\n",
    "for setting in settings3:\n",
    "    ca = CA(grid_size=[20, 20], **setting['params'])\n",
    "    ca.init_grid(\"random\", 4)\n",
    "    ca.run(10000)\n",
    "    df_raster = ca.collect_raster_data(3000)\n",
    "    df = raster_to_basic(df_raster)\n",
    "    sigma = branching_prameter(df)\n",
    "    print(sigma)\n",
    "    if(abs(sigma-1) < 0.05):\n",
    "        settings4.append(setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(abs(branching_prameter(df)-1) < 0.05):\n",
    "        df_transmission = raster_to_transmission(df_raster)\n",
    "        avalanche = transmission_to_avalanche(df_transmission)\n",
    "        avalanche_df = avalanche_to_statistics(avalanche)\n",
    "        avalanche_df.to_csv(path, index=True)    \n",
    "        paths_avalanche.append(path)\n",
    "        print(\"Data written to:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Spike Density vs. Branching Ratio m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot avg_spike_density vs. m\n",
    "settings2 = [{\"name\": f\"ref{ref}thresh{thresh}p{p}r{False}\", \n",
    "            \"params\": {\"threshold\": thresh, \n",
    "                        \"refractory_period\": ref, \n",
    "                        \"probability_of_spontaneous_activity\": p, \n",
    "                        \"max_distance\": 3, \n",
    "                        \"random_connection\": False}}\n",
    "            for ref in range(1, 8) for thresh in range(1, 7) for p in [0.015,0.02,0.025]]\n",
    "# The write data is neglected in this ipynb for clarification. It's similar to what we did to the settings1.\n",
    "paths = [f\"data/spikes_CA_ref_thresh/spikes_CA_{setting['name']}.csv\" for setting in settings2]\n",
    "size = 50\n",
    "spike_density_plot(paths, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot avg_spike_density vs. m considering refractory period \n",
    "settings2 = [{\"name\": f\"ref{ref}thresh{thresh}p{p}r{False}\", \n",
    "            \"params\": {\"threshold\": thresh, \n",
    "                        \"refractory_period\": ref, \n",
    "                        \"probability_of_spontaneous_activity\": p, \n",
    "                        \"max_distance\": 3, \n",
    "                        \"random_connection\": False}}\n",
    "            for ref in range(1, 8) for thresh in range(1, 7) for p in [0.015,0.02,0.025]]\n",
    "# The write data is neglected in this ipynb for clarification. It's similar to what we did to the settings1.\n",
    "paths = [f\"data/spikes_CA_ref_thresh/spikes_CA_{setting['name']}.csv\" for setting in settings2]\n",
    "refs = [setting['params']['refractory_period'] for setting in settings2]\n",
    "size = 50\n",
    "ref_spike_density_plot(paths, size, refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avalanche size/duration distribution (distinguishing origins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avalanches = []\n",
    "# This for loop takes a long time to run.\n",
    "# You can just run the third cell to load the data from the csv files.\n",
    "for i in range(20):\n",
    "    # This is a parameter setting we selcted which sigma is near 1.\n",
    "    ca = CA(grid_size=[50, 50], refractory_period=3,threshold=2,probability_of_spontaneous_activity=0.02,max_distance=3,random_connection=False)\n",
    "    raster_df = ca.collect_raster_data(1000)\n",
    "    df = raster_to_basic(raster_df)\n",
    "    df_transmission = raster_to_transmission(raster_df)\n",
    "    avalanche = transmission_to_avalanche(df_transmission)\n",
    "    avalanche_df = avalanche_to_statistics(avalanche)\n",
    "    avalanches.append(avalanche)\n",
    "all_avalanches = [item for sublist in avalanches for item in sublist]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avalanche_df = avalanche_to_statistics(all_avalanches)\n",
    "avalanche_df.to_csv(\"data/avalanche_powerlaw_df.csv\", index=True)\n",
    "avalanches_by_length = defaultdict(list)\n",
    "for av in all_avalanches:\n",
    "    avalanches_by_length[len(av)].append(av)\n",
    "mean_activities = {length: np.mean(np.array(avs), axis=0) for length, avs in avalanches_by_length.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to get plot directly\n",
    "df = load_data_csv(\"data/avalanche_powerlaw_df.csv\")\n",
    "avalanche_sizes = df['size'].tolist()\n",
    "fit = powerlaw.Fit(avalanche_sizes)\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "plt.style.use('tableau-colorblind10') \n",
    "\n",
    "fit.plot_pdf(ax=ax,linestyle='None', marker='o', markersize=4, label='Original Distribution')\n",
    "fit.power_law.plot_pdf(linestyle='--', ax=ax, label='Powerlaw Fitting Distribution')\n",
    "plt.legend(fontsize=14)\n",
    "plt.xlabel(\"Avalanche Size\", fontsize=16)\n",
    "plt.ylabel(\"Probability Density\", fontsize=16)\n",
    "plt.title(\"Avalanche Size Distribution\", fontsize=17)\n",
    "plt.show()\n",
    "print('Tau (τ) - Power-law exponent:', fit.power_law.alpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [f\"data/spikes_CA_avalanche_grid/spikes_CA_synchronous.csv\"]# Change the path to get diffenrent activity plots\n",
    "spike_activity_plot(paths, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spike Density vs timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings3 = [{\"name\": f\"ref{ref}thresh{t}p{p}r{r}\", \n",
    "            \"params\": {\"threshold\": t, \n",
    "                        \"refractory_period\": ref, \n",
    "                        \"probability_of_spontaneous_activity\": p, \n",
    "                        \"max_distance\": 3, \n",
    "                        \"random_connection\": r}}\n",
    "            for ref in range(1, 8) for t in range(1, 8) for p in [0.015, 0.02, 0.025] for r in [False, True]]\n",
    "paths = [f\"data/spikes_CA_ref_thresh/spikes_CA_{setting['name']}.csv\" for setting in settings3]\n",
    "for path in paths:\n",
    "    df = pd.read_csv(path)\n",
    "    r = branching_prameter(df)\n",
    "    if(abs(r - 1) < 0.05):\n",
    "        print(\"paths: \", path)\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"data/spikes_CA_ref_thresh/spikes_CA_ref2thresh3p0.02rFalse.csv\",\n",
    "         \"data/spikes_CA_ref_thresh/spikes_CA_ref4thresh4p0.015rFalse.csv\",\n",
    "         \"data/spikes_CA_ref_thresh/spikes_CA_ref6thresh6p0.015rTrue.csv\"]\n",
    "size = 50\n",
    "grid_activity_timestep(paths, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale-free Property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avalanches = []\n",
    "# This loop takes a long time to run. \n",
    "# To get the result figure we showed in the presentation, you can just run the third block in this section.\n",
    "for i in range(10): \n",
    "    ca = CA(grid_size=[50, 50], refractory_period=3,threshold=2,probability_of_spontaneous_activity=0.02,max_distance=3,random_connection=False)\n",
    "    raster_df = ca.collect_raster_data(1000)\n",
    "    df = raster_to_basic(raster_df)\n",
    "    df_transmission = raster_to_transmission(raster_df)\n",
    "    avalanche = transmission_to_avalanche(df_transmission)\n",
    "    avalanches.append(avalanche)\n",
    "all_avalanches = [item for sublist in avalanches for item in sublist]\n",
    "print(all_avalanches)\n",
    "avalanches_by_length = defaultdict(list)\n",
    "for av in all_avalanches:\n",
    "    avalanches_by_length[len(av)].append(av)\n",
    "mean_activities = {length: np.mean(np.array(avs), axis=0) for length, avs in avalanches_by_length.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the all_avalnches to csv\n",
    "df = pd.DataFrame({'avalanches': all_avalanches})\n",
    "df.to_csv('data/avalanche_statistics_scalefree.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avalanche size vs. avalanche duration for scale-fee property\n",
    "df = load_data_csv(\"data/avalanche_statistics_scalefree.csv\")\n",
    "all_avalanches = df['avalanches'].apply(eval).tolist()\n",
    "avalanches_by_length = defaultdict(list)\n",
    "for av in all_avalanches:\n",
    "    avalanches_by_length[len(av)].append(av)\n",
    "mean_activities = {length: np.mean(np.array(avs), axis=0) for length, avs in avalanches_by_length.items()}\n",
    "plt.figure(figsize=(6, 5)) \n",
    "plt.title(\"Scale-free Property\", fontsize=14)\n",
    "plt.xlabel(\"Avalanche Durations\", fontsize=14)\n",
    "plt.ylabel(\"Avalanche Sizes\", fontsize=14)\n",
    "plt.grid(True)\n",
    "for length, mean_activity in mean_activities.items():\n",
    "    if length < 15 and length > 3:\n",
    "        plt.plot(range(length), mean_activity, label=f'Duration {length}', color='blue', alpha=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression(Not used in the presentation)\n",
    "mean_activities = {length: np.mean(np.array(avs), axis=0) for length, avs in avalanches_by_length.items()}\n",
    "durations = []\n",
    "sizes = []\n",
    "for duration, activities in mean_activities.items():\n",
    "    if duration < 17 and duration > 5:\n",
    "        durations.append(duration)\n",
    "        sizes.append(np.mean(activities))\n",
    "log_durations = np.log(durations).reshape(-1, 1)\n",
    "log_sizes = np.log(sizes)\n",
    "model = LinearRegression()\n",
    "model.fit(log_durations, log_sizes)\n",
    "predicted = model.predict(log_durations)\n",
    "gamma = model.coef_[0]\n",
    "r2 = r2_score(log_sizes, predicted)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(log_durations, log_sizes, color='black', label='Data points')\n",
    "plt.plot(log_durations, predicted, color='red', label=f'Linear fit: γ = {gamma:.2f}, R² = {r2:.2f}')\n",
    "plt.legend()\n",
    "plt.xlabel('Log(duration)')\n",
    "plt.ylabel('Log(size)')\n",
    "plt.title('Log-Log Plot of Avalanche Duration vs Size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the scalefree with zooming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5)) \n",
    "plt.title(\"Scale-free Property\", fontsize=14)\n",
    "plt.xlabel(\"Avalanche Durations\", fontsize=14)\n",
    "plt.ylabel(\"Avalanche Sizes\", fontsize=14)\n",
    "plt.grid(True)\n",
    "for length, mean_activity in mean_activities.items():\n",
    "    if length < 15 and length > 5 :\n",
    "        scaled_time = [i / (length - 1) for i in range(length)]\n",
    "        scaled_activity = [activity / ((length) ** (2- 1)) for activity in mean_activity]\n",
    "        plt.plot(scaled_time, scaled_activity, label=f'Duration {length}', color='blue', alpha=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Testing varying parameters to catch the phase transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average density of active neurons of varying threshold(max_height) with different refractory periods\n",
    "\n",
    "threshold_values = range(1, 10)\n",
    "refractory_periods = [2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for refractory_period in refractory_periods:\n",
    "    average_densities = []\n",
    "\n",
    "    for threshold in threshold_values:\n",
    "        file_name = f\"data/new_varying_threshold_{threshold}_ref_{refractory_period}.csv\"\n",
    "        data = pd.read_csv(file_name)\n",
    "\n",
    "        average_density = data[\"spikes_total\"].mean() / (50 * 50)\n",
    "        average_densities.append(average_density)\n",
    "\n",
    "    plt.plot(threshold_values, average_densities, marker='o', label=f'Refractory {refractory_period}')\n",
    "\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Average Density of Active Neurons')\n",
    "plt.title('Density-Threshold Phase Transitions for Different Refractory Periods')\n",
    "\n",
    "plt.legend(title=\"Refractory Periods\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Branching parameter of varying thresholds at different refractory periods\n",
    "\n",
    "branching_params_by_ref = {rp: [] for rp in refractory_periods}\n",
    "\n",
    "for rp in refractory_periods:\n",
    "    for threshold in threshold_values:\n",
    "        file_name = f\"data/new_varying_threshold_{threshold}_ref_{rp}.csv\"\n",
    "        data = pd.read_csv(file_name)\n",
    "        sigma= branching_prameter(data)\n",
    "        branching_params_by_ref[rp].append(sigma)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for rp, branching_params in branching_params_by_ref.items():\n",
    "    plt.plot(threshold_values, branching_params, marker='o', label=f'Refractory{rp}')\n",
    "\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Branching Parameter')\n",
    "plt.title('Branching Parameter vs. Threshold for Different Refractory Periods')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table for different combination of threshold and refractory period\n",
    "\n",
    "refractory_periods = range(1, 8)\n",
    "heights = range(1, 7)\n",
    "\n",
    "branching_params_df = pd.DataFrame(index=refractory_periods, columns=heights)\n",
    "\n",
    "for rp in refractory_periods:\n",
    "    for h in heights:\n",
    "        file_name = f'data/ref_{rp}_threshold_{h}.csv'\n",
    "        if os.path.exists(file_name):\n",
    "            data = pd.read_csv(file_name)\n",
    "            sigma = branching_prameter(data)\n",
    "            branching_params_df.loc[rp, h] = sigma\n",
    "\n",
    "        else:\n",
    "            print(f\"File {file_name} not found.\")\n",
    "\n",
    "branching_params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Branching parameters of continuous theshold values\n",
    "\n",
    "threshold_values = np.arange(1.0, 8.1, 0.1)\n",
    "branching_params = []\n",
    "\n",
    "# Loop through each threshold value, read the CSV file and calculate the branching parameter\n",
    "for threshold in threshold_values:\n",
    "    file_name = f\"data/new_varying_threshold_{threshold:.1f}.csv\"  # Adjust filename pattern as necessary\n",
    "    data = pd.read_csv(file_name)\n",
    "    \n",
    "    # Calculate the branching parameter using the function from data_utils.py\n",
    "    sigma = branching_prameter(data)\n",
    "    branching_params.append(sigma)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(threshold_values, branching_params, marker='o')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Branching Parameter')\n",
    "plt.title('Branching Parameter vs. Threshold')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComputationalEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
