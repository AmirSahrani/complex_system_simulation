{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quasi-criticality in the Cortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Setup notebook environment -q flag suppresses output, if you want to see it, remove the -q flag'''\n",
    "# %pip install -r requirements.txt -q\n",
    "from utils.plotting_utils import *\n",
    "from utils.data_utils import *\n",
    "from utils.utils import *\n",
    "from branching import BranchingNeurons\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import powerlaw\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- loglog size vs duration\n",
    "- dynamic range\n",
    "- information transfer\n",
    "- susceptibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Branching model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TESTING = True \n",
    "file = 'data/branching_data_densities.csv'\n",
    "if not os.path.exists(file) or TESTING:\n",
    "    if TESTING:\n",
    "        os.remove(file)\n",
    "    for branching_ratio in tqdm(np.logspace(np.log10(0.5), np.log10(5), 20)):\n",
    "        for i in [0,1,3,5]:\n",
    "            kwargs = {\n",
    "                'N': 100,\n",
    "                'max_neighbors': 28,\n",
    "                'cooldown': i,\n",
    "                'branching_ratio': branching_ratio,\n",
    "                'visual': False,\n",
    "            }\n",
    "            data = simulate(BranchingNeurons, n_runs=10, duration=10000, **kwargs)\n",
    "            write_data(data, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTING = False\n",
    "file = 'data/branching_data_final.csv'\n",
    "if not os.path.exists(file) or TESTING:\n",
    "    if TESTING:\n",
    "        pass\n",
    "    for branching_ratio in tqdm(np.logspace(np.log10(0.5), np.log10(5), 20)):\n",
    "        kwargs = {\n",
    "            'N': 2500,\n",
    "            'max_neighbors': 28,\n",
    "            'branching_ratio': branching_ratio,\n",
    "            'visual': False,\n",
    "        }\n",
    "        data = simulate(BranchingNeurons, n_runs=10, duration=10000, **kwargs)\n",
    "        write_data(data, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/branching_data_final.csv', header=0, index_col=0)\n",
    "data['mean_density'] = data['density'].apply(float)\n",
    "data['evalanche_duration'] = data['evalanche_duration'].apply(str_to_list)\n",
    "data['evalanche_size'] = data['evalanche_size'].apply(str_to_list)\n",
    "\n",
    "data['density_duration'] = data.apply(lambda x: get_density(x['evalanche_duration'])[0], axis=1)\n",
    "data['density_size'] = data.apply(lambda x: get_density(x['evalanche_size'])[0], axis=1)\n",
    "data['values_duration'] = data.apply(lambda x: get_density(x['evalanche_duration'])[1], axis=1)\n",
    "data['values_size'] = data.apply(lambda x: get_density(x['evalanche_size'])[1], axis=1)\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_branching = data.groupby('branching_ratio').mean(numeric_only=True)\n",
    "critical_point = closest_index_to_value(grouped_branching.index, 1)\n",
    "critical_data = grouped_branching.loc[grouped_branching.index == grouped_branching.index[critical_point]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'N': 500,\n",
    "    'max_neighbors': 28,\n",
    "    'branching_ratio': None,\n",
    "    'visual': False,\n",
    "}\n",
    "plot_activity_per_time_step(10000, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(grouped_branching.index, grouped_branching['emperical_branching_ratio'], label='Branching ratio')\n",
    "plt.plot(np.linspace(np.min(grouped_branching.index), np.max(grouped_branching.index), 100), np.linspace(0, np.max(grouped_branching.index), 100), label='1:1 line', color='black', linestyle='--' , alpha=0.5)\n",
    "plt.xlabel('Branching ratio')\n",
    "plt.ylabel('Emperical branching ratio')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cooldowns = pd.read_csv('data/branching_data_densities.csv', header=0, index_col=0)\n",
    "grouped_cooldowns = data_cooldowns.groupby(['cooldown', 'branching_ratio']).agg({'density': ['mean', 'std']})\n",
    "\n",
    "for i in [0,1,3,5]:\n",
    "    plt.plot(grouped_cooldowns.loc[i].index, grouped_cooldowns.loc[i]['density']['mean'], label=f'Cooldown {i}')\n",
    "    plt.fill_between(grouped_cooldowns.loc[i].index, grouped_cooldowns.loc[i]['density']['mean'] - grouped_cooldowns.loc[i]['density']['std'], grouped_cooldowns.loc[i]['density']['mean'] + grouped_cooldowns.loc[i]['density']['std'], alpha=0.2)\n",
    "plt.xlabel('Branching ratio')\n",
    "plt.ylabel('Density')\n",
    "plt.xlim(0.5, 5)\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(grouped_branching.index, grouped_branching['mean_density'])\n",
    "plt.scatter(grouped_branching.index, grouped_branching['mean_density'])\n",
    "\n",
    "plt.scatter(grouped_branching.index.values[critical_point], grouped_branching['mean_density'].values[critical_point], c='r')\n",
    "plt.text(grouped_branching.index.values[critical_point] + 0.2, grouped_branching['mean_density'].values[critical_point], 'Critical Point')\n",
    "plt.xlabel('Branching Ratio')\n",
    "plt.xlim(0.5, 3)\n",
    "plt.ylabel('Mean Density')\n",
    "plt.title('Mean Density vs Branching Ratio')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loglog_plotting(type: str, data: pd.DataFrame, grouped_branching: pd.DataFrame):\n",
    "    fig, ax =plt.subplots(3,2, figsize=(15,15))\n",
    "    ax = ax.ravel()\n",
    "    for i in range(6):\n",
    "        offset = 4\n",
    "\n",
    "        all_critical_points =  data.loc[data['branching_ratio'] == grouped_branching.index[offset+i]]\n",
    "        all_data = np.concatenate(all_critical_points[type].values)\n",
    "        all_data = all_data[all_data > 0]\n",
    "\n",
    "        fit = powerlaw.Fit(all_data, verbose=False)\n",
    "        lognormal = powerlaw.Lognormal(verbose=False)\n",
    "        lognormal.fit(all_data)\n",
    "        mu, sigma = lognormal.mu, lognormal.sigma\n",
    "\n",
    "        log_llkhood, p_value = fit.distribution_compare('power_law', 'lognormal', normalized_ratio=True)\n",
    "\n",
    "        x_values = np.linspace(min(all_data), max(all_data), len(all_data))\n",
    "        fitted_line = (x_values ** -fit.alpha)\n",
    "        log_fitted = lognormal.pdf(x_values)\n",
    "        \n",
    "\n",
    "        powerlaw.plot_pdf(all_data, ax=ax[i], color='red', label='Empirical data' , linestyle='None', marker='o', markersize=3, alpha=0.5)\n",
    "        ax[i].plot(x_values, fitted_line, color='black', linestyle='--', label='Power law fit')\n",
    "        ax[i].plot(x_values, log_fitted, color='blue', linestyle='--', label='Log Normal fit')\n",
    "\n",
    "        ax[i].set_title(f'Branching ratio: {grouped_branching.index[offset+i]:.2f}')\n",
    "        ax[i].text(0.1, 0.1, \n",
    "           f'$\\\\alpha$: {fit.alpha:.2f}\\n$\\\\mu$: {mu:.2f}\\n$\\\\sigma$: {sigma:.2f}\\n$p$: {p_value:.3f}\\nLog Likelihood: {log_llkhood:.3f}', \n",
    "           transform=ax[i].transAxes)\n",
    "\n",
    "        ax[i].set_xlabel(type.split('_')[0].capitalize() + ' ' + type.split('_')[1])\n",
    "        ax[i].set_ylabel('Frequency')\n",
    "        \n",
    "        if i == 1:\n",
    "            ax[i].legend(loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def loglog_plotting_size_duration(type: List[str], data: pd.DataFrame, grouped_branching: pd.DataFrame):\n",
    "    fig, ax =plt.subplots(3,2, figsize=(15,15))\n",
    "    ax = ax.ravel()\n",
    "    for i in range(6):\n",
    "        offset = 4\n",
    "\n",
    "        all_data=  data.loc[data['branching_ratio'] == grouped_branching.index[offset+i]]\n",
    "\n",
    "        all_size = np.concatenate(all_data[type[0]].values)\n",
    "        all_size = all_size[all_size > 0]\n",
    "\n",
    "        all_duration = np.concatenate(all_data[type[1]].values)\n",
    "        all_duration = all_duration[all_duration > 0]\n",
    "\n",
    "\n",
    "\n",
    "        ax[i].set_title(f'Branching ratio: {grouped_branching.index[offset+i]:.2f}')\n",
    "        ax[i].loglog(all_size, all_duration, color='red', linestyle='None', marker='o', markersize=3, alpha=0.5)\n",
    "        ax[i].set_xlabel(type[0].split('_')[0].capitalize() + ' ' + type[0].split('_')[1])\n",
    "        ax[i].set_xlabel(type[1].split('_')[0].capitalize() + ' ' + type[1].split('_')[1])\n",
    "\n",
    "        if i == 1:\n",
    "            ax[i].legend(loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglog_plotting(\"evalanche_duration\", data, grouped_branching)\n",
    "loglog_plotting(\"evalanche_size\", data, grouped_branching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglog_plotting_size_duration(['evalanche_size', 'evalanche_duration'], data, grouped_branching)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BTW-like model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings1 = [\n",
    "    {\"name\": \"round_spiral\", \"params\": {\"height\": 4, \"refractory_period\": 5, \"probability_of_spontaneous_activity\": 0.02, \"max_distance\": 3, \"random_connection\": False}},\n",
    "    {\"name\": \"pulse_wave\", \"params\": {\"height\": 5, \"refractory_period\": 4, \"probability_of_spontaneous_activity\": 0.03, \"max_distance\": 3, \"random_connection\": False}},\n",
    "    {\"name\": \"synchronous\", \"params\": {\"height\": 3, \"refractory_period\": 5, \"probability_of_spontaneous_activity\": 0.015, \"max_distance\": 2.5, \"random_connection\": True}},\n",
    "    {\"name\": \"oscillatory\", \"params\": {\"height\": 2, \"refractory_period\": 4, \"probability_of_spontaneous_activity\": 0.02, \"max_distance\": 3, \"random_connection\": False}},\n",
    "    {\"name\": \"repeating\", \"params\": {\"height\": 2, \"refractory_period\": 4, \"probability_of_spontaneous_activity\": 0.02, \"max_distance\": 3, \"random_connection\": True}},\n",
    "    {\"name\": \"random\", \"params\": {\"height\": 5, \"refractory_period\": 5, \"probability_of_spontaneous_activity\": 0.02, \"max_distance\": 3, \"random_connection\": False}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collection\n",
    "for setting in settings1:\n",
    "    btw = BTW(grid_size=[50, 50], **setting['params'])\n",
    "    btw.run(10000)\n",
    "    path = f\"data/spikes_btw_{setting['name']}.csv\"\n",
    "    btw.write_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot avg_spike_density vs. m\n",
    "paths = [f\"data/spikes_btw_{setting['name']}.csv\" for setting in settings1]\n",
    "size = 50\n",
    "spike_density_plot(paths, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings2 = [{\"name\": f\"ref{ref}thresh{thresh}\", \n",
    "            \"params\": {\"height\": thresh, \n",
    "                        \"refractory_period\": ref, \n",
    "                        \"probability_of_spontaneous_activity\": 0.02, \n",
    "                        \"max_distance\": 3, \n",
    "                        \"random_connection\": False}}\n",
    "            for ref in range(1, 8) for thresh in range(1, 7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collection\n",
    "for setting in settings2:\n",
    "    btw = BTW(grid_size=[50, 50], **setting['params'])\n",
    "    btw.init_grid(\"random\", 4)\n",
    "    btw.run(10000)\n",
    "    path = f\"data/spikes_btw_ref_thresh/spikes_btw_{setting['name']}.csv\"\n",
    "    btw.write_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot avg_spike_density vs. m\n",
    "paths = [f\"data/spikes_btw_ref_thresh/spikes_btw_{setting['name']}.csv\" for setting in settings2]\n",
    "size = 50\n",
    "spike_density_plot(paths, size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Draft**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 3, 3]\n",
    "b = [0, 3, 2]\n",
    "a-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "args = {\"one\": 4, \"two\": 5, \"three\": 0.02}\n",
    "args_df = pd.DataFrame(args, index=[0])\n",
    "results_df = pd.DataFrame({\"spikes_total\": np.array([0, 3, 3]), \n",
    "                        \"spikes_neighbours\": np.array([0, 1, 1]), \n",
    "                        \"spikes_input\": np.array([0, 3, 3]) - np.array([0, 1, 1])})\n",
    "combined_df = pd.concat([args_df, results_df], axis=1)\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = load_data_csv(\"path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComputationalEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
