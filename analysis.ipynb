{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quasi-criticality in the Cortex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Setup notebook environment -q flag suppresses output, if you want to see it, remove the -q flag'''\n",
    "# %pip install -r requirements.txt -q\n",
    "from utils.plotting_utils import *\n",
    "from utils.data_utils import *\n",
    "from utils.utils import *\n",
    "from branching import BranchingNeurons\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import powerlaw\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "from sandpile import BTW\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Branching model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first section of this notebook will be investigating the behavior of a branching model. This model is a simple branching process, where each neuron has a probability of firing, and if it does, it will fire to a number of other neurons. This is a simple model of the branching of neurons in the cortex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Files should be available in the data folder, if not, run the code below. It may take a while !!\n",
    "file = 'data/branching_data_densities.csv'\n",
    "if not os.path.exists(file):\n",
    "    for branching_ratio in tqdm(np.logspace(np.log10(0.5), np.log10(5), 20)):\n",
    "        for i in [0,1,3,5]:\n",
    "            kwargs = {\n",
    "                'N': 100,\n",
    "                'max_neighbors': 28,\n",
    "                'cooldown': i,\n",
    "                'branching_ratio': branching_ratio,\n",
    "                'visual': False,\n",
    "            }\n",
    "            data = simulate(BranchingNeurons, n_runs=10, duration=10000, **kwargs)\n",
    "            write_data(data, file)\n",
    "\n",
    "\n",
    "file = 'data/branching_data_final.csv'\n",
    "if not os.path.exists(file):\n",
    "    for branching_ratio in tqdm(np.logspace(np.log10(0.5), np.log10(5), 20)):\n",
    "        kwargs = {\n",
    "            'N': 2500,\n",
    "            'max_neighbors': 28,\n",
    "            'branching_ratio': branching_ratio,\n",
    "            'visual': False,\n",
    "        }\n",
    "        data = simulate(BranchingNeurons, n_runs=10, duration=10000, **kwargs)\n",
    "        write_data(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/branching_data_final.csv', header=0, index_col=0)\n",
    "data['mean_density'] = data['density'].apply(float)\n",
    "data['evalanche_duration'] = data['evalanche_duration'].apply(str_to_list)\n",
    "data['evalanche_size'] = data['evalanche_size'].apply(str_to_list)\n",
    "\n",
    "data['density_duration'] = data.apply(lambda x: get_density(x['evalanche_duration'])[0], axis=1)\n",
    "data['density_size'] = data.apply(lambda x: get_density(x['evalanche_size'])[0], axis=1)\n",
    "data['values_duration'] = data.apply(lambda x: get_density(x['evalanche_duration'])[1], axis=1)\n",
    "data['values_size'] = data.apply(lambda x: get_density(x['evalanche_size'])[1], axis=1)\n",
    "\n",
    "\n",
    "grouped_branching = data.groupby('branching_ratio').mean(numeric_only=True)\n",
    "critical_point = closest_index_to_value(grouped_branching.index, 1)\n",
    "critical_data = grouped_branching.loc[grouped_branching.index == grouped_branching.index[critical_point]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavior over time for different branching ratios\n",
    "We can see that for different branching ratios, the behavior of the system changes. For a branching ratio of 1.1 (because of system size we correct the branching ratio upward a little bit), the system is at a critical point, and the activations quickly increase but die out after a period of activiy. For a branching ratio of 0.8, the system will die out, and for a branching ratio of 2, the system tend to chaos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'N': 500,\n",
    "    'max_neighbors': 28,\n",
    "    'branching_ratio': None,\n",
    "    'visual': False,\n",
    "}\n",
    "plot_activity_per_time_step(10000, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the emperical branching ratio\n",
    "When we manually calculate the branching ratio, we find that the branching ratio does not the same as the one we set. This is because the branching ratio is a function of the system size, and the system size is not large enough to get a good estimate of the branching ratio. This is a common problem in the study of criticality in the cortex, and is known as the \"finite size effect\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_emperical_branching_ratio(grouped_branching)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase transition\n",
    "When plotting the mean activity of the system over time, we can see that the system goes through a phase transition at a branching ratio of 1. This is a critical point, and the system will go from a state of low activity to a state of high activity. This is a phase transition, and is a common feature of critical systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_density_vs_branching_ratio(grouped_branching, critical_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on the activity\n",
    "We noticed the mean activity of the system does not approach 1, we suspect this might also be because the system size is not large enough to get a good estimate of the mean activity. We also suspected the refractory period of the neurons might also affect the mean activity of the system, but looking at the figure below comparing the mean activity of the system for different refractory periods, we can see that the refractory period only decreases the mean activity of the system, and does not affect the phase transition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cooldowns = pd.read_csv('data/branching_data_densities.csv', header=0, index_col=0)\n",
    "grouped_cooldowns = data_cooldowns.groupby(['cooldown', 'branching_ratio']).agg({'density': ['mean', 'std']})\n",
    "\n",
    "\n",
    "plot_phase_transition_cooldowns(grouped_cooldowns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avalanche distributions\n",
    "Below we plot the avalanche distributions for their size and duration. In both we notice no statistically significant results for the power law distribution, which is a common feature of critical systems. Although we do note that the figures visually look very much like a power law distribution. We also see that around the branching ratio these distributions become more power law like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['avalanche_duration'] = data['evalanche_duration']\n",
    "data['avalanche_size'] = data['evalanche_size']\n",
    "loglog_plotting(\"avalanche_duration\", data, grouped_branching)\n",
    "loglog_plotting(\"avalanche_size\", data, grouped_branching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglog_plotting_size_duration(['evalanche_size', 'evalanche_duration'], data, grouped_branching)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information flow\n",
    "> We will be investigating the following information transfer properties of the branching model:\n",
    "> 1. The information transfer between the input and the output layer\n",
    "> 2. The dynamic range of the information transfer between the input and the output layer \n",
    "> 3. The interaction between network size and peak information transfer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branching_ratios = np.linspace(0.2, 3, 15)\n",
    "input_nums = list(range(1, 100, 2))\n",
    "mutual_infos = []\n",
    "dynamic_ranges = []\n",
    "susceptibilities = []\n",
    "susceptibilities_error = []\n",
    "\n",
    "for branching_ratio in branching_ratios:\n",
    "    kwargs = {\n",
    "        'N': 100,\n",
    "        'max_neighbors': 8,\n",
    "        'branching_ratio': branching_ratio,\n",
    "        'cooldown': 0,\n",
    "        'visual': False,\n",
    "    }\n",
    "    sim = BranchingNeurons(**kwargs)\n",
    "    output_nums = []\n",
    "    sus_list = []\n",
    "\n",
    "    for input_num in input_nums:\n",
    "        spike_history = []\n",
    "        for _ in range(10):\n",
    "            running_average = []\n",
    "            sim.reset()\n",
    "\n",
    "            neurons_to_activate = np.random.choice(sim.neurons, input_num, replace=False)\n",
    "\n",
    "            assert len(neurons_to_activate) == input_num\n",
    "\n",
    "            for neuron in neurons_to_activate:\n",
    "                neuron.active = True\n",
    "                sim.active.append(neuron)\n",
    "\n",
    "            for i in range(10):\n",
    "                sim.run(1, random_adding=False)\n",
    "                running_average.append(sum([neuron.active for neuron in sim.neurons]))\n",
    "\n",
    "            spike_history.append(np.mean(running_average))\n",
    "\n",
    "        output_nums.append(spike_history[-1])\n",
    "        sus_list.append(susceptibility(spike_history, 100))\n",
    "    mutual_infos.append(mutual_info(input_nums, output_nums))\n",
    "    dynamic_ranges.append(dynamic_range(output_nums))\n",
    "    susceptibilities.append(np.mean(sus_list))\n",
    "    susceptibilities_error.append(np.std(sus_list)/np.sqrt(len(sus_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dynamic_range_plot(spike_num: list, probability: list, branching_ratio: float, ax: plt.plot = None) -> None:\n",
    "    \"\"\"\n",
    "    Plot the dynamic range of a certain branching ratio.\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    plt.style.use('tableau-colorblind10')\n",
    "    plt.grid(True)\n",
    "    ax.plot(spike_num, probability, label = f\"Branching Ratio = {branching_ratio:.2f}\", markersize=3, alpha=0.8)\n",
    "    # ax.set_xlabel(\"Response, number of neurons\", fontsize=14)\n",
    "    # ax.set_ylabel(\"Probability (Response)\", fontsize=14)\n",
    "    ax.set_ylim((0,0.2))\n",
    "    # ax.set_xlim(0, 35)\n",
    "    # ax.set_title('Dynamic Ranges', fontsize=16)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "# Show the dynamic range of a certain branching ratio\n",
    "width = []\n",
    "for i, branching_ratio in enumerate(branching_ratios):\n",
    "    probs = np.cumsum(dynamic_ranges[i][1])\n",
    "    probs_r = 1 - probs\n",
    "    start = np.argmax(probs > 0.1)\n",
    "    end = np.argmax(probs > 0.9)\n",
    "    width.append(len(dynamic_ranges[i][1][start:end]))\n",
    "\n",
    "std_err = np.std(width) / np.sqrt(len(width))\n",
    "plt.style.use('tableau-colorblind10')\n",
    "plt.grid(True)\n",
    "plt.errorbar(branching_ratios, width, yerr=std_err, fmt='--', markersize=3, alpha=0.8)\n",
    "plt.xlabel(\"Branching Ratio\", fontsize=14)\n",
    "plt.ylabel(\"Dynamic Range (width)\", fontsize=14)\n",
    "plt.title('Dynamic Ranges vs Branching Ratios', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show susceptibility vs. branching ratio\n",
    "susceptibility_plot(susceptibilities, susceptibilities_error, branching_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BTW-like model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### df: index, spikes_total, spikes_input, spikes_neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For different patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings1 = [\n",
    "    {\"name\": \"round_spiral\", \"params\": {\"height\": 4, \"refractory_period\": 5, \"probability_of_spontaneous_activity\": 0.02, \"max_distance\": 3, \"random_connection\": False}},\n",
    "    {\"name\": \"pulse_wave\", \"params\": {\"height\": 5, \"refractory_period\": 3, \"probability_of_spontaneous_activity\": 0.03, \"max_distance\": 3, \"random_connection\": False}},\n",
    "    {\"name\": \"synchronous\", \"params\": {\"height\": 3, \"refractory_period\": 5, \"probability_of_spontaneous_activity\": 0.015, \"max_distance\": 2.5, \"random_connection\": True}},\n",
    "    {\"name\": \"oscillatory\", \"params\": {\"height\": 2, \"refractory_period\": 4, \"probability_of_spontaneous_activity\": 0.02, \"max_distance\": 3, \"random_connection\": False}},\n",
    "    {\"name\": \"repeating\", \"params\": {\"height\": 2, \"refractory_period\": 4, \"probability_of_spontaneous_activity\": 0.02, \"max_distance\": 3, \"random_connection\": True}},\n",
    "    {\"name\": \"random\", \"params\": {\"height\": 5, \"refractory_period\": 5, \"probability_of_spontaneous_activity\": 0.02, \"max_distance\": 3, \"random_connection\": False}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collection to csv in df: spikes_input, spikes_neighbours, spikes_total per time step\n",
    "for setting in settings1:\n",
    "    btw = BTW(grid_size=[50, 50], **setting['params'])\n",
    "    btw.run(10000)\n",
    "    path = f\"data/spikes_btw_{setting['name']}.csv\"\n",
    "    btw.write_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see what's the pattern like for different patterns\n",
    "paths = [f\"data/spikes_btw_{setting['name']}.csv\" for setting in settings1]\n",
    "for path in paths:\n",
    "    df = load_data_csv(path)\n",
    "    sigma = branching_prameter(df)\n",
    "    print(path, sigma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more parameters settings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### df: avalanche_size, avalanche_duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is used to store raster data, which is not used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for setting in settings2:\n",
    "    btw = BTW(grid_size=[50, 50], **setting['params'])\n",
    "    btw.init_grid(\"random\", 4)\n",
    "    btw.run(10000)\n",
    "    path = f\"data/spikes_btw_avalanche/spikes_btw_{setting['name']}.csv\"\n",
    "    btw.collect_raster_data(10000, path) # This function: collect raster data was once used to collect raster data in csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is used to store raster data for different patterns, which is also used plot spike activity figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for setting in settings1:\n",
    "    btw = BTW(grid_size=[20, 20], ** setting['params'])\n",
    "    btw.init_grid(\"random\", 4)\n",
    "    btw.run(1500)\n",
    "    path = f\"data/spikes_btw_avalanche_grid/spikes_btw_{setting['name']}.csv\"\n",
    "    df = btw.collect_raster_data(5000)\n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is used to store avalanche data, which is also used to plot power law distributions later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings3 = [{\"name\": f\"ref{ref}thresh{thresh}p{p}\", \n",
    "            \"params\": {\"height\": thresh, \n",
    "                        \"refractory_period\": ref, \n",
    "                        \"probability_of_spontaneous_activity\": p, \n",
    "                        \"max_distance\": 3, \n",
    "                        \"random_connection\": False}}\n",
    "            for ref in range(2, 8) for thresh in range(2, 8) for p in [0.015, 0.02, 0.025]]\n",
    "paths_avalanche = []\n",
    "settings4 = []\n",
    "for setting in settings3:\n",
    "    btw = BTW(grid_size=[20, 20], **setting['params'])\n",
    "    btw.init_grid(\"random\", 4)\n",
    "    btw.run(10000)\n",
    "    df_raster = btw.collect_raster_data(3000)\n",
    "    df = raster_to_basic(df_raster)\n",
    "    sigma = branching_prameter(df)\n",
    "    print(sigma)\n",
    "    if(abs(sigma-1) < 0.05):\n",
    "        settings4.append(setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(abs(branching_prameter(df)-1) < 0.05):\n",
    "        df_transmission = raster_to_transmission(df_raster)\n",
    "        avalanche = transmission_to_avalanche(df_transmission)\n",
    "        avalanche_df = avalanche_to_statistics(avalanche)\n",
    "        avalanche_df.to_csv(path, index=True)    \n",
    "        paths_avalanche.append(path)\n",
    "        print(\"Data written to:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Spike Density vs. Branching Ratio m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot avg_spike_density vs. m\n",
    "settings2 = [{\"name\": f\"ref{ref}thresh{thresh}p{p}r{False}\", \n",
    "            \"params\": {\"height\": thresh, \n",
    "                        \"refractory_period\": ref, \n",
    "                        \"probability_of_spontaneous_activity\": p, \n",
    "                        \"max_distance\": 3, \n",
    "                        \"random_connection\": False}}\n",
    "            for ref in range(1, 8) for thresh in range(1, 7) for p in [0.015,0.02,0.025]]\n",
    "# The write data is neglected in this ipynb for clarification. It's similar to what we did to the settings1.\n",
    "paths = [f\"data/spikes_btw_ref_thresh/spikes_btw_{setting['name']}.csv\" for setting in settings2]\n",
    "size = 50\n",
    "spike_density_plot(paths, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot avg_spike_density vs. m considering refractory period \n",
    "settings2 = [{\"name\": f\"ref{ref}thresh{thresh}p{p}r{False}\", \n",
    "            \"params\": {\"height\": thresh, \n",
    "                        \"refractory_period\": ref, \n",
    "                        \"probability_of_spontaneous_activity\": p, \n",
    "                        \"max_distance\": 3, \n",
    "                        \"random_connection\": False}}\n",
    "            for ref in range(1, 8) for thresh in range(1, 7) for p in [0.015,0.02,0.025]]\n",
    "# The write data is neglected in this ipynb for clarification. It's similar to what we did to the settings1.\n",
    "paths = [f\"data/spikes_btw_ref_thresh/spikes_btw_{setting['name']}.csv\" for setting in settings2]\n",
    "refs = [setting['params']['refractory_period'] for setting in settings2]\n",
    "size = 50\n",
    "ref_spike_density_plot(paths, size, refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avalanche size/duration distribution (distinguishing origins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avalanches = []\n",
    "# This for loop takes a long time to run.\n",
    "# You can just run the third cell to load the data from the csv files.\n",
    "for i in range(20):\n",
    "    # This is a parameter setting we selcted which sigma is near 1.\n",
    "    btw = BTW(grid_size=[50, 50], refractory_period=3,height=2,probability_of_spontaneous_activity=0.02,max_distance=3,random_connection=False)\n",
    "    raster_df = btw.collect_raster_data(1000)\n",
    "    df = raster_to_basic(raster_df)\n",
    "    df_transmission = raster_to_transmission(raster_df)\n",
    "    avalanche = transmission_to_avalanche(df_transmission)\n",
    "    avalanche_df = avalanche_to_statistics(avalanche)\n",
    "    avalanches.append(avalanche)\n",
    "all_avalanches = [item for sublist in avalanches for item in sublist]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avalanche_df = avalanche_to_statistics(all_avalanches)\n",
    "avalanche_df.to_csv(\"data/avalanche_powerlaw_df.csv\", index=True)\n",
    "avalanches_by_length = defaultdict(list)\n",
    "for av in all_avalanches:\n",
    "    avalanches_by_length[len(av)].append(av)\n",
    "mean_activities = {length: np.mean(np.array(avs), axis=0) for length, avs in avalanches_by_length.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to get plot directly\n",
    "df = load_data_csv(\"data/avalanche_powerlaw_df.csv\")\n",
    "avalanche_sizes = df['size'].tolist()\n",
    "fit = powerlaw.Fit(avalanche_sizes)\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "plt.style.use('tableau-colorblind10') \n",
    "\n",
    "fit.plot_pdf(ax=ax,linestyle='None', marker='o', markersize=4, label='Original Distribution')\n",
    "fit.power_law.plot_pdf(linestyle='--', ax=ax, label='Powerlaw Fitting Distribution')\n",
    "plt.legend(fontsize=14)\n",
    "plt.xlabel(\"Avalanche Size\", fontsize=16)\n",
    "plt.ylabel(\"Probability Density\", fontsize=16)\n",
    "plt.title(\"Avalanche Size Distribution\", fontsize=17)\n",
    "plt.show()\n",
    "print('Tau (τ) - Power-law exponent:', fit.power_law.alpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [f\"data/spikes_btw_avalanche_grid/spikes_btw_synchronous.csv\"]# Change the path to get diffenrent activity plots\n",
    "spike_activity_plot(paths, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spike Density vs timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings3 = [{\"name\": f\"ref{ref}thresh{t}p{p}r{r}\", \n",
    "            \"params\": {\"height\": t, \n",
    "                        \"refractory_period\": ref, \n",
    "                        \"probability_of_spontaneous_activity\": p, \n",
    "                        \"max_distance\": 3, \n",
    "                        \"random_connection\": r}}\n",
    "            for ref in range(1, 8) for t in range(1, 8) for p in [0.015, 0.02, 0.025] for r in [False, True]]\n",
    "paths = [f\"data/spikes_btw_ref_thresh/spikes_btw_{setting['name']}.csv\" for setting in settings3]\n",
    "for path in paths:\n",
    "    df = pd.read_csv(path)\n",
    "    r = branching_prameter(df)\n",
    "    if(abs(r - 1) < 0.05):\n",
    "        print(\"paths: \", path)\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"data/spikes_btw_ref_thresh/spikes_btw_ref2thresh3p0.02rFalse.csv\",\n",
    "         \"data/spikes_btw_ref_thresh/spikes_btw_ref4thresh4p0.015rFalse.csv\",\n",
    "         \"data/spikes_btw_ref_thresh/spikes_btw_ref6thresh6p0.015rTrue.csv\"]\n",
    "size = 50\n",
    "grid_activity_timestep(paths, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale-free Property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avalanches = []\n",
    "# This loop takes a long time to run. \n",
    "# To get the result figure we showed in the presentation, you can just run the third block in this section.\n",
    "for i in range(10): \n",
    "    btw = BTW(grid_size=[50, 50], refractory_period=3,height=2,probability_of_spontaneous_activity=0.02,max_distance=3,random_connection=False)\n",
    "    raster_df = btw.collect_raster_data(1000)\n",
    "    df = raster_to_basic(raster_df)\n",
    "    df_transmission = raster_to_transmission(raster_df)\n",
    "    avalanche = transmission_to_avalanche(df_transmission)\n",
    "    avalanches.append(avalanche)\n",
    "all_avalanches = [item for sublist in avalanches for item in sublist]\n",
    "print(all_avalanches)\n",
    "avalanches_by_length = defaultdict(list)\n",
    "for av in all_avalanches:\n",
    "    avalanches_by_length[len(av)].append(av)\n",
    "mean_activities = {length: np.mean(np.array(avs), axis=0) for length, avs in avalanches_by_length.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the all_avalnches to csv\n",
    "df = pd.DataFrame({'avalanches': all_avalanches})\n",
    "df.to_csv('data/avalanche_statistics_scalefree.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avalanche size vs. avalanche duration for scale-fee property\n",
    "df = load_data_csv(\"data/avalanche_statistics_scalefree.csv\")\n",
    "all_avalanches = df['avalanches'].apply(eval).tolist()\n",
    "avalanches_by_length = defaultdict(list)\n",
    "for av in all_avalanches:\n",
    "    avalanches_by_length[len(av)].append(av)\n",
    "mean_activities = {length: np.mean(np.array(avs), axis=0) for length, avs in avalanches_by_length.items()}\n",
    "plt.figure(figsize=(6, 5)) \n",
    "plt.title(\"Scale-free Property\", fontsize=14)\n",
    "plt.xlabel(\"Avalanche Durations\", fontsize=14)\n",
    "plt.ylabel(\"Avalanche Sizes\", fontsize=14)\n",
    "plt.grid(True)\n",
    "for length, mean_activity in mean_activities.items():\n",
    "    if length < 15 and length > 3:\n",
    "        plt.plot(range(length), mean_activity, label=f'Duration {length}', color='blue', alpha=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression(Not used in the presentation)\n",
    "mean_activities = {length: np.mean(np.array(avs), axis=0) for length, avs in avalanches_by_length.items()}\n",
    "durations = []\n",
    "sizes = []\n",
    "for duration, activities in mean_activities.items():\n",
    "    if duration < 17 and duration > 5:\n",
    "        durations.append(duration)\n",
    "        sizes.append(np.mean(activities))\n",
    "log_durations = np.log(durations).reshape(-1, 1)\n",
    "log_sizes = np.log(sizes)\n",
    "model = LinearRegression()\n",
    "model.fit(log_durations, log_sizes)\n",
    "predicted = model.predict(log_durations)\n",
    "gamma = model.coef_[0]\n",
    "r2 = r2_score(log_sizes, predicted)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(log_durations, log_sizes, color='black', label='Data points')\n",
    "plt.plot(log_durations, predicted, color='red', label=f'Linear fit: γ = {gamma:.2f}, R² = {r2:.2f}')\n",
    "plt.legend()\n",
    "plt.xlabel('Log(duration)')\n",
    "plt.ylabel('Log(size)')\n",
    "plt.title('Log-Log Plot of Avalanche Duration vs Size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the scalefree with zooming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5)) \n",
    "plt.title(\"Scale-free Property\", fontsize=14)\n",
    "plt.xlabel(\"Avalanche Durations\", fontsize=14)\n",
    "plt.ylabel(\"Avalanche Sizes\", fontsize=14)\n",
    "plt.grid(True)\n",
    "for length, mean_activity in mean_activities.items():\n",
    "    if length < 15 and length > 5 :\n",
    "        scaled_time = [i / (length - 1) for i in range(length)]\n",
    "        scaled_activity = [activity / ((length) ** (2- 1)) for activity in mean_activity]\n",
    "        plt.plot(scaled_time, scaled_activity, label=f'Duration {length}', color='blue', alpha=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Testing varying parameters to catch the phase transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_values = range(1, 10)\n",
    "average_densities = []\n",
    "\n",
    "for height in height_values:\n",
    "    file_name = f\"data/new_varying_height_{height}.csv\"\n",
    "    data = pd.read_csv(file_name)\n",
    "\n",
    "    average_density = data['spikes_total'].mean() / (50 * 50)\n",
    "    average_densities.append(average_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_values = range(1, 10)\n",
    "refractory_periods = [2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for refractory_period in refractory_periods:\n",
    "    average_densities = []\n",
    "\n",
    "    for height in height_values:\n",
    "        file_name = f\"data/new_varying_height_{height}_ref_{refractory_period}.csv\"\n",
    "        data = pd.read_csv(file_name)\n",
    "\n",
    "        average_density = data[\"spikes_total\"].mean() / (50 * 50)\n",
    "        average_densities.append(average_density)\n",
    "\n",
    "    plt.plot(height_values, average_densities, marker='o', label=f'Refractory {refractory_period}')\n",
    "\n",
    "plt.xlabel('Height')\n",
    "plt.ylabel('Average Density of Active Neurons')\n",
    "plt.title('Density-Height Phase Transitions for Different Refractory Periods')\n",
    "\n",
    "plt.legend(title=\"Refractory Periods\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branching_params_by_ref = {rp: [] for rp in refractory_periods}\n",
    "\n",
    "for rp in refractory_periods:\n",
    "    for height in height_values:\n",
    "        file_name = f\"data/new_varying_height_{height}_ref_{rp}.csv\"\n",
    "        data = pd.read_csv(file_name)\n",
    "        sigma= branching_prameter(data)\n",
    "        branching_params_by_ref[rp].append(sigma)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for rp, branching_params in branching_params_by_ref.items():\n",
    "    plt.plot(height_values, branching_params, marker='o', label=f'Refractory{rp}')\n",
    "\n",
    "plt.xlabel('Height')\n",
    "plt.ylabel('Branching Parameter')\n",
    "plt.title('Branching Parameter vs. Height for Different Refractory Periods')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(height_values, average_densities, marker='o')\n",
    "plt.xlabel('Height')\n",
    "plt.ylabel('Average Density of Active Neurons')\n",
    "plt.title('Density-Height Phase Transitions')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branching_params = []\n",
    "\n",
    "for height in height_values:\n",
    "    filename = f\"data/new_varying_height_{height}.csv\"\n",
    "    data = pd.read_csv(filename)\n",
    "    sigma = branching_prameter(data)\n",
    "    branching_params.append(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(height_values, branching_params, marker='o')\n",
    "plt.xlabel('Height')\n",
    "plt.ylabel('Branching Parameter')\n",
    "plt.title('Branching Parameter vs. Height')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_to_check = [3, 4]\n",
    "branching_parameters = {}\n",
    "\n",
    "for height in height_to_check:\n",
    "    file_name = f\"data/varying_height_{height}.csv\"\n",
    "    data = pd.read_csv(file_name)\n",
    "    sigma = branching_prameter(data)  # Ensure the function name is correctly spelled as 'branching_parameter'\n",
    "    branching_parameters[height] = sigma\n",
    "\n",
    "print(branching_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refractory_period_values = range(1, 10)\n",
    "average_densities_1 = []\n",
    "\n",
    "for refractory_period in refractory_period_values:\n",
    "    filename = f\"data/new_varying_refractory_{refractory_period}.csv\"\n",
    "    data_1 = pd.read_csv(filename)\n",
    "\n",
    "    average_density_1 = data_1['spikes_total'].mean() / (50 * 50)\n",
    "    average_densities_1.append(average_density_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(refractory_period_values, average_densities_1, marker='o')\n",
    "plt.title(\"Refractory Period vs. Average Density of Active Neurons\")\n",
    "plt.xlabel(\"Refractory Period\")\n",
    "plt.ylabel(\"Average Density of Active Neurons\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refractory_period_to_check = [3, 4]\n",
    "branching_parameters = {}\n",
    "\n",
    "for refractory_period in refractory_period_to_check:\n",
    "    file_name = f\"data/new_varying_refractory_{refractory_period}.csv\"\n",
    "    data = pd.read_csv(file_name)\n",
    "    sigma = branching_prameter(data)\n",
    "    branching_parameters[refractory_period] = sigma\n",
    "\n",
    "print(branching_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branching_params = []\n",
    "\n",
    "for refractory_period in refractory_period_values:\n",
    "    filename = f\"data/new_varying_refractory_{refractory_period}.csv\"\n",
    "    data = pd.read_csv(filename)\n",
    "    sigma = branching_prameter(data)\n",
    "    branching_params.append(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(refractory_period_values, branching_params, marker='o')\n",
    "plt.xlabel('Refractory Period')\n",
    "plt.ylabel('Branching Parameter')\n",
    "plt.title('Branching Parameter vs. Refractory Period')\n",
    "plt.grid(True)\n",
    "plt.ylim([min(branching_params) - 0.6, max(branching_params) + 0.6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic for presentation:\n",
    "### Motivation\n",
    "### Data we use: self-generated?\n",
    "### Hypothesis\n",
    "### What we did:\n",
    "#### CA Model: \n",
    "##### How is this Model like？\n",
    "1. Rules: \n",
    "   1. We have a 2d grid. \n",
    "   2. Interact rule: The neighbour neurons around spikes are going to be added 1 to their grid number. If in ths time step, neurons who get enough gird number, which means reaches the threshold, becomes a spike_neighbour in the next time step. And if they donot reach the threshold, their grid numbers will be cleared to zero.\n",
    "   3. Refractory period: After 1 timestep, a spike will get into the refractory period, which means within the next refractoy period timesteps, the spike will get activated whatever happens.\n",
    "   4. Spontaneous spike rule: We have this spontaneous_input_probability p to make random unactivated and also not in refractory period neurons to activate and become a spike_input.\n",
    "   5. So, we have a big timestep for loop, we first make all spikes into refractory period and also make spikes in refractory period in time -1 refractory period. This will take effect at the next timestep. Then we check neighbours to create spikes_neighbours and then we add_grains to make spikes_input.\n",
    "2. Parameters(max_height,refractory_period,spontaneous_input_probability,random_connection，max_distance)\n",
    "##### What we get: \n",
    "1. By playing with the parameters tuning, we find patterns(vedios and raster figure). \n",
    "2. While running on different settings of parameters, we find the phase transition around branching ratio =1.\n",
    "3. While changing only one parameter (let's say a) each time, we find the interesting relationship beween spike_density and a. In principle, what we are doing is changing branching ratio. However, the relationship is different for different a. You see it looks like first-order phase transition, but we think actually it's not. It may be just because of our activation rule is adding 1 to your neighbours at one time, but not 0.3 or 0.5. So the data we get is discrete.\n",
    "4. We tried to delve into the powerlaw distribution of avalanche size and distribution and the relationship between these 2 /tao, but the results we get is for avalanche size, it clearly follows powerlaw distribution, but for avalanche duration distribution, it seems not. We think it's due to in the CA model we implemented, the avalanches tend to merge into one big avalanche. Even though we have implemented a complicated algorithm to track avalanche origins, we still cannot prevent avalanches merging into one big avalanche. So the avalanche data we get often ends with one very big avalanche size and duration number. \n",
    "So we want to implement this branching model with random network to make up for the shortcomings of existing models in studying avalanche size and duration distribution.\n",
    "#### Branching model\n",
    "##### Model definition\n",
    "> We create N neurons, all of which get a number of neighbors, unless this is not possible, in which case they might get less. Most neurons will have the same number of neurons. Each edge has a directional probaility of passing on an activation. The sum of these activations is the branching ratio, which is our control parameter. The density of the neurons is defined as the number of neurons that is active at a time step, and is the order parameter.\n",
    "\n",
    "##### Information transfer\n",
    "> Although we technically don't have a feedforward model, we can take each time step as a feedforward step. The information is transferred from the neurons that are active to the neurons that are connected to them. The information is transferred with a probability p, which is the branching ratio. We expect the information transfer to be the \"longest\", meaning the correlation between time steps is the highest, when the branching ratio is 1. This is because the information is will on average not \"spread\" dilute into chaos or die out. When the branching ratio is lower than 1, the information is lost, and when it is higher than 1, the activations will cause too many new activations, thereby leave no information about the original activation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComputationalEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
